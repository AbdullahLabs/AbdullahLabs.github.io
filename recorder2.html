<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Conversation Analyzer</title>
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
    <script src="https://unpkg.com/@tailwindcss/browser@latest"></script>
    <style>
      /* Custom styles for the message box */
      #message-box {
        position: fixed;
        top: 20px;
        left: 50%;
        transform: translateX(-50%);
        background-color: rgba(0, 0, 0, 0.7);
        color: white;
        padding: 16px;
        border-radius: 6px;
        z-index: 10;
        opacity: 0;
        transition: opacity 0.3s ease-in-out, transform 0.3s ease-in-out;
      }
      #message-box.show {
        opacity: 1;
        transform: translateX(-50%) translateY(0);
      }
      #message-box.error {
        background-color: rgba(255, 0, 0, 0.8);
      }
    </style>
</head>
<body class="bg-gray-100 font-inter">
    <div class="container mx-auto p-4">
        <h1 class="text-3xl font-semibold text-gray-800 mb-6 text-center">Voice Conversation Analyzer</h1>

        <div id="message-box" class="hidden"></div>

        <div class="tab-container flex mb-4">
            <button data-tab="record-tab" class="tab active px-4 py-2 rounded-l-md bg-white shadow-md">Record</button>
            <button data-tab="history-tab" class="tab px-4 py-2 rounded-r-md bg-white shadow-md">History</button>
        </div>

        <div class="tab-content" id="record-tab-content">
            <div class="record-controls bg-white p-6 rounded-lg shadow-md mb-6 flex flex-col items-center gap-4">
                <div id="recording-visualizer" class="w-full h-24 bg-gray-200 rounded-md">
                    <canvas id="audio-visualizer" class="w-full h-full"></canvas>
                </div>
                <div class="flex gap-4">
                    <button id="start-recording" class="px-6 py-2 bg-blue-500 text-white rounded-md hover:bg-blue-600 transition-colors duration-200">Start Recording</button>
                    <button id="stop-recording" class="px-6 py-2 bg-red-500 text-white rounded-md hover:bg-red-600 transition-colors duration-200 hidden">Stop Recording</button>
                </div>
                <div class="text-center">
                    <p id="recording-status" class="text-gray-600">Click Start to Record</p>
                </div>
            </div>

            <div class="recording-results bg-white p-6 rounded-lg shadow-md">
                <h2 class="text-xl font-semibold text-gray-800 mb-4">Transcription</h2>
                <div id="transcription-text" class="text-gray-700 p-4 border border-gray-300 rounded-md mb-4 overflow-y-auto max-h-48"></div>
                <h2 class="text-xl font-semibold text-gray-800 mb-4">Speaker Diarization</h2>
                <div id="speaker-diarization" class="text-gray-700 p-4 border border-gray-300 rounded-md mb-4 overflow-y-auto max-h-48"></div>
                <h2 class="text-xl font-semibold text-gray-800 mb-4">Summary</h2>
                <div id="summary-text" class="text-gray-700 p-4 border border-gray-300 rounded-md overflow-y-auto max-h-48"></div>
            </div>
        </div>

        <div class="tab-content hidden" id="history-tab-content">
            <div id="conversation-history" class="bg-white p-6 rounded-lg shadow-md">
                <h2 class="text-xl font-semibold text-gray-800 mb-4">Conversation History</h2>
                <ul id="history-list" class="space-y-3">
                    </ul>
            </div>
        </div>
    </div>

    <script src="https://cdn.jsdelivr.net/npm/@xenova/transformers@2.13.4/dist/transformers.min.js"></script>
    <script>
    // Helper function to display messages
    function showMessage(message, type = 'info') {
        const messageBox = document.getElementById('message-box');
        messageBox.textContent = message;
        messageBox.className = `fixed top-4 left-1/2 transform -translate-x-1/2 bg-${type === 'error' ? 'red' : 'green'}-500 text-white px-4 py-2 rounded shadow-lg z-50`;
        messageBox.classList.add('show');
        setTimeout(() => {
            messageBox.classList.remove('show');
        }, 3000);
    }

    // --- UI Elements ---
    const startRecordingButton = document.getElementById('start-recording');
    const stopRecordingButton = document.getElementById('stop-recording');
    const recordingStatus = document.getElementById('recording-status');
    const transcriptionText = document.getElementById('transcription-text');
    const speakerDiarizationText = document.getElementById('speaker-diarization');
    const summaryText = document.getElementById('summary-text');
    const historyList = document.getElementById('history-list');
    const recordTabButton = document.querySelector('[data-tab="record-tab"]');
    const historyTabButton = document.querySelector('[data-tab="history-tab"]');
    const recordTabContent = document.getElementById('record-tab-content');
    const historyTabContent = document.getElementById('history-tab-content');
    const audioVisualizerCanvas = document.getElementById('audio-visualizer');
    const audioVisualizerContext = audioVisualizerCanvas.getContext('2d');

    let audioChunks = [];
    let mediaRecorder;
    let audioStream;
    let isRecording = false;
    let conversationHistory = [];
    const sampleRate = 16000; // Define the sample rate

    // --- Tabs ---
    recordTabButton.addEventListener('click', () => {
        recordTabButton.classList.add('active');
        historyTabButton.classList.remove('active');
        recordTabContent.classList.remove('hidden');
        historyTabContent.classList.add('hidden');
    });

    historyTabButton.addEventListener('click', () => {
        historyTabButton.classList.add('active');
        recordTabButton.classList.remove('active');
        historyTabContent.classList.remove('hidden');
        recordTabContent.classList.add('hidden');
        loadConversationHistory();
    });

    // --- Helper Functions ---
    function disableButton(button) {
        button.disabled = true;
        button.classList.add('opacity-50', 'cursor-not-allowed');
    }

    function enableButton(button) {
        button.disabled = false;
        button.classList.remove('opacity-50', 'cursor-not-allowed');
    }

    function clearRecordingResults() {
        transcriptionText.textContent = '';
        speakerDiarizationText.textContent = '';
        summaryText.textContent = '';
    }

    // --- Recording ---
    async function setupRecording() {
        try {
            audioStream = await navigator.mediaDevices.getUserMedia({ audio: true });
            mediaRecorder = new MediaRecorder(audioStream, { mimeType: 'audio/wav' }); // Use audio/wav
            mediaRecorder.ondataavailable = (event) => {
                audioChunks.push(event.data);
            };

            mediaRecorder.onstop = () => {
                const audioBlob = new Blob(audioChunks, { type: 'audio/wav' }); // Ensure type is audio/wav
                processAudio(audioBlob);
                audioChunks = [];
            };

            // Setup audio visualizer
            const audioContext = new AudioContext();
            const analyser = audioContext.createAnalyser();
            const microphone = audioContext.createMediaStreamSource(audioStream);
            microphone.connect(analyser);
            analyser.fftSize = 256;
            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);

            function drawVisualizer() {
                if (!isRecording) return; // Stop if not recording
                requestAnimationFrame(drawVisualizer);
                analyser.getByteFrequencyData(dataArray);
                audioVisualizerContext.clearRect(0, 0, audioVisualizerCanvas.width, audioVisualizerCanvas.height);
                audioVisualizerContext.fillStyle = 'rgba(0, 123, 255, 0.7)'; // Blue with opacity
                const barWidth = (audioVisualizerCanvas.width / bufferLength) * 2.5;
                let x = 0;
                for (let i = 0; i < bufferLength; i++) {
                    const barHeight = dataArray[i] / 2;
                    audioVisualizerContext.fillRect(x, audioVisualizerCanvas.height - barHeight / 2, barWidth, barHeight);
                    x += barWidth + 1;
                }
            }
            drawVisualizer(); // Start the visualizer
        } catch (error) {
            console.error('Error setting up recording:', error);
            showMessage(`Error setting up recording: ${error.message}`, 'error');
        }
    }

    startRecordingButton.addEventListener('click', async () => {
        if (!mediaRecorder) {
            await setupRecording();
        }
        clearRecordingResults();
        audioChunks = [];
        mediaRecorder.start();
        isRecording = true;
        startRecordingButton.classList.add('hidden');
        stopRecordingButton.classList.remove('hidden');
        recordingStatus.textContent = 'Recording...';
        disableButton(stopRecordingButton); // Disable stop button initially
        setTimeout(() => {
            enableButton(stopRecordingButton); // Enable after a short delay
        }, 100);
    });

    stopRecordingButton.addEventListener('click', () => {
        if (mediaRecorder && isRecording) {
            mediaRecorder.stop();
            isRecording = false;
            startRecordingButton.classList.remove('hidden');
            stopRecordingButton.classList.add('hidden');
            recordingStatus.textContent = 'Recording stopped. Processing...';
        }
        if (audioStream) {
            audioStream.getTracks().forEach(track => track.stop());
        }
    });

    // --- Audio Processing (Placeholder) ---
    async function processAudio(audioBlob) {
      try {
        const arrayBuffer = await audioBlob.arrayBuffer();

        // Transcribe audio with placeholder
        const transcription = await transcribeAudio(arrayBuffer);
        transcriptionText.textContent = transcription;

        // Speaker diarization placeholder
        const diarization = "Speaker 1: Hello, how are you?\nSpeaker 2: I'm good, thanks!";
        speakerDiarizationText.textContent = diarization;

        // Summary placeholder
        const summary = "This conversation is a brief greeting between two speakers.";
        summaryText.textContent = summary;

        // Simulate processing delay and update UI
        setTimeout(() => {
            recordingStatus.textContent = 'Ready to Record';
            saveConversation({
                audio: audioBlob,
                transcription: transcription,
                diarization: diarization,
                summary: summary,
                timestamp: new Date().toLocaleString(),
            });
        }, 2000); // Simulate a 2-second processing delay
    } catch (error) {
        console.error("Error processing audio: ", error);
        showMessage(`Error processing audio: ${error.message}`, 'error');
        recordingStatus.textContent = 'Ready to Record'; // Reset status
    }
}

    async function transcribeAudio(arrayBuffer) {
        try {
            // Placeholder:  Normally you would use Whisper here.
            //  Load the model (this is the correct way to load in the browser)
            // const model = await transformers.pipeline('automatic-speech-recognition', 'Xenova/whisper-tiny.en');
            // const output = await model(audioData);
            // return output.text;

            // Simulate transcription for the example.
            await new Promise(resolve => setTimeout(resolve, 1000)); // Simulate 1 second delay
            return "Simulated transcription: This is a test transcription.";

        } catch (error) {
            console.error("Transcription error", error);
            showMessage(`Transcription failed: ${error.message}`, 'error');
            return "Transcription Failed."; // Important:  Return a string, not undefined.
        }
    }

    // --- Data Management ---
    function saveConversation(conversation) {
        conversationHistory.push(conversation);
        localStorage.setItem('conversationHistory', JSON.stringify(conversationHistory));
        loadConversationHistory(); // Update history display
    }

    function loadConversationHistory() {
        const savedHistory = localStorage.getItem('conversationHistory');
        if (savedHistory) {
            conversationHistory = JSON.parse(savedHistory);
            historyList.innerHTML = ''; // Clear old history
            conversationHistory.forEach((item, index) => {
                const listItem = document.createElement('li');
                listItem.classList.add('bg-gray-50', 'border', 'border-gray-200', 'rounded-md', 'p-4', 'shadow-sm');
                listItem.innerHTML = `
                    <h3 class="font-semibold text-gray-800 mb-2">Conversation ${index + 1} - ${item.timestamp}</h3>
                    <p class="text-gray-700 mb-2"><strong>Transcription:</strong> ${item.transcription}</p>
                    <p class="text-gray-700 mb-2"><strong>Diarization:</strong> ${item.diarization}</p>
                    <p class="text-gray-700"><strong>Summary:</strong> ${item.summary}</p>
                    <button class="view-audio bg-blue-500 hover:bg-blue-700 text-white font-bold py-2 px-4 rounded mt-2" data-audio-url="${URL.createObjectURL(item.audio)}">View Audio</button>
                `;
                historyList.appendChild(listItem);
            });

             // Attach event listeners to the "View Audio" buttons *after* they are added to the DOM
            document.querySelectorAll('.view-audio').forEach(button => {
                button.addEventListener('click', function() {
                    const audioUrl = this.getAttribute('data-audio-url');
                    const audio = new Audio(audioUrl);
                    audio.play();
                });
            });
        } else {
            historyList.innerHTML = '<p class="text-gray-500">No conversations recorded yet.</p>';
        }
    }

    // --- Initial Setup ---
    if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
        // getUserMedia is supported
        startRecordingButton.disabled = false;
    } else {
        // getUserMedia is not supported
        showMessage('Microphone access is not supported in this browser.', 'error');
        startRecordingButton.disabled = true;
    }

    // Load history on page load
    loadConversationHistory();
    </script>
</body>
</html>
